{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoJkhV0TDmzjuS9gONA9Fl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["################### GPU 이용시 설치 ###################\n","\n","# 1. 기존 버전 제거 (충돌 방지)\n","!pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse\n","\n","# 2. PyTorch 2.4.1 + CUDA 12.1 설치\n","# (Colab의 기본 CUDA 버전과 맞추는 것이 좋습니다)\n","!pip install torch==2.4.1+cu121 torchvision==0.19.1+cu121 torchaudio==2.4.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n","\n","# 3. PyG 의존성 설치 (버전 매칭 필수: torch-2.4.0+cu121)\n","# 주의: Torch가 2.4.1이어도 PyG wheel은 보통 2.4.0 경로를 공유합니다.\n","!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n","\n","# 4. PyG 메인 설치\n","!pip install torch-geometric\n","\n","# [중요] 설치 후 런타임 재시작이 필요할 수 있습니다.\n","import torch\n","print(f\"Torch: {torch.__version__}\")\n","print(f\"CUDA Available: {torch.cuda.is_available()}\")"],"metadata":{"id":"aDLvn_PwQD97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################### CPU 이용시 설치 ###################\n","# 1. 기존 제거\n","!pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse\n","\n","# 2. PyTorch 2.4.1 (CPU 전용) 설치\n","# --index-url을 지정하여 CPU 전용 가벼운 바이너리를 받습니다.\n","!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cpu\n","\n","# 3. PyG 의존성 설치 (CPU용 Wheel)\n","!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n","\n","# 4. PyG 메인 설치\n","!pip install torch-geometric\n","import torch\n","print(f\"Torch: {torch.__version__}\")\n","print(f\"CUDA Available: {torch.cuda.is_available()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"7XK0YCv3Qgjp","executionInfo":{"status":"ok","timestamp":1765359228254,"user_tz":-540,"elapsed":81067,"user":{"displayName":"심현우","userId":"05027025761987939753"}},"outputId":"f26d303a-6f6d-44d3-a33a-e96360534138"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.9.0+cu126\n","Uninstalling torch-2.9.0+cu126:\n","  Successfully uninstalled torch-2.9.0+cu126\n","Found existing installation: torchvision 0.24.0+cu126\n","Uninstalling torchvision-0.24.0+cu126:\n","  Successfully uninstalled torchvision-0.24.0+cu126\n","Found existing installation: torchaudio 2.9.0+cu126\n","Uninstalling torchaudio-2.9.0+cu126:\n","  Successfully uninstalled torchaudio-2.9.0+cu126\n","\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cpu\n","Collecting torch==2.4.1\n","  Downloading https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp312-cp312-linux_x86_64.whl (194.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.19.1\n","  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.19.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.4.1\n","  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.4.1%2Bcpu-cp312-cp312-linux_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (4.15.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (2025.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (75.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.1) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n","Installing collected packages: torch, torchvision, torchaudio\n","Successfully installed torch-2.4.1+cpu torchaudio-2.4.1+cpu torchvision-0.19.1+cpu\n","Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_scatter-2.1.2%2Bpt24cpu-cp312-cp312-linux_x86_64.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcpu/torch_sparse-0.6.18%2Bpt24cpu-cp312-cp312-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-scatter, torch-sparse\n","Successfully installed torch-scatter-2.1.2+pt24cpu torch-sparse-0.6.18+pt24cpu\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n","Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.7.0\n","Torch: 2.4.1+cpu\n","CUDA Available: False\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import TransformerConv\n","from torch_geometric.nn.models.tgn import (\n","    TGNMemory,\n","    IdentityMessage,\n","    LastAggregator\n",")\n","import numpy as np\n","\n","# 장치 설정 (Colab 런타임 유형에 따라 자동 변경)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# 하이퍼파라미터 설정\n","num_nodes = 100\n","num_events = 1000  # 전체 이벤트 수\n","dim_msg = 16       # 메시지 벡터 차원\n","dim_memory = 32    # 메모리 차원\n","dim_emb = 32       # 임베딩 차원\n","dim_time = 32      # 시간 인코딩 차원"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjHd6KZURrK5","executionInfo":{"status":"ok","timestamp":1765359465709,"user_tz":-540,"elapsed":14938,"user":{"displayName":"심현우","userId":"05027025761987939753"}},"outputId":"5472b5d4-cb82-4333-c221-0bb5f69efaf8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"code","source":["# 가상의 이벤트 데이터 생성 (Source -> Destination, Time, Message)\n","# 시간(t)은 반드시 오름차순이어야 하므로 정렬합니다.\n","src = torch.randint(0, num_nodes, (num_events,)).to(device)\n","dst = torch.randint(0, num_nodes, (num_events,)).to(device)\n","t = torch.sort((torch.rand(num_events) * 1000).long())[0].to(device) #TGN은 기본적으로 시간을 long으로 정의\n","msg = torch.randn(num_events, dim_msg).to(device)\n","\n","# 학습/테스트 분할 (8:2)\n","split = int(num_events * 0.8)\n","\n","train_data = {\n","    'src': src[:split],\n","    'dst': dst[:split],\n","    't': t[:split],\n","    'msg': msg[:split]\n","}\n","\n","test_data = {\n","    'src': src[split:],\n","    'dst': dst[split:],\n","    't': t[split:],\n","    'msg': msg[split:]\n","}\n","\n","print(f\"Train events: {len(train_data['src'])}, Test events: {len(test_data['src'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TInnNDwRshY","executionInfo":{"status":"ok","timestamp":1765365812310,"user_tz":-540,"elapsed":26,"user":{"displayName":"심현우","userId":"05027025761987939753"}},"outputId":"379cd64f-32e0-46f0-86cd-ccbdac521011"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Train events: 800, Test events: 200\n"]}]},{"cell_type":"code","source":["#https://pytorch-geometric.readthedocs.io/en/2.7.0/_modules/torch_geometric/nn/models/tgn.html\n","#https://github.com/pyg-team/pytorch_geometric/blob/master/examples/tgn.py\n","class ToyTGN(nn.Module):\n","    def __init__(self, num_nodes, raw_msg_dim, memory_dim, time_dim, embedding_dim):\n","        super().__init__()\n","\n","        # (A) 메모리 모듈: 노드의 과거 상태 저장\n","        self.memory = TGNMemory(\n","            num_nodes=num_nodes,\n","            raw_msg_dim=raw_msg_dim,\n","            memory_dim=memory_dim,\n","            time_dim=time_dim,\n","            message_module=IdentityMessage(raw_msg_dim, memory_dim, time_dim),\n","            aggregator_module=LastAggregator()\n","        )\n","\n","        # (B) 그래프 임베딩 레이어 (TransformerConv)\n","        self.gnn = TransformerConv(\n","            in_channels=memory_dim,\n","            out_channels=embedding_dim,\n","            heads=2,\n","            concat=False\n","        )\n","\n","        # (C) 링크 예측기 (Decoder)\n","        self.link_pred = nn.Sequential(\n","            nn.Linear(embedding_dim * 2, embedding_dim),\n","            nn.ReLU(),\n","            nn.Linear(embedding_dim, 1)\n","        )\n","\n","    def forward(self, src, dst, t, msg):\n","        # 1. 최신 메모리 상태 조회 (Look-up)\n","        z_src = self.memory(src)[0]\n","        z_dst = self.memory(dst)[0]\n","\n","        # 2. 임베딩 생성 (간소화: Neighbor Sampling 없이 메모리 직접 사용)\n","        # 빈 edge_index를 넣어 self-loop 개념으로 처리\n","        empty_edge = torch.zeros((2, 0), dtype=torch.long, device=device)\n","        emb_src = self.gnn(z_src, edge_index=empty_edge)\n","        emb_dst = self.gnn(z_dst, edge_index=empty_edge)\n","\n","        # 3. 링크 예측 (확률값 계산)\n","        pred = self.link_pred(torch.cat([emb_src, emb_dst], dim=1))\n","\n","        # 4. 메모리 업데이트 (현재 배치의 정보를 기록)\n","        print(src.dtype, dst.dtype, t.dtype, msg.dtype)\n","        self.memory.update_state(src, dst, t, msg)\n","\n","\n","        return pred"],"metadata":{"id":"CusQSSxqRuDB","executionInfo":{"status":"ok","timestamp":1765365813156,"user_tz":-540,"elapsed":31,"user":{"displayName":"심현우","userId":"05027025761987939753"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["model = ToyTGN(num_nodes, dim_msg, dim_memory, dim_time, dim_emb).to(device)\n","\n","# TGNMemory의 last_update 버퍼가 float 타입이어야 하는데 long으로 초기화되는 버그 수정\n","# (torch_geometric 2.7.0 버전에서 발생하는 문제로 추정)\n","model.memory.last_update = model.memory.last_update.to(torch.float)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","print(\"Model initialized.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmTO_yq4RvFY","executionInfo":{"status":"ok","timestamp":1765365813250,"user_tz":-540,"elapsed":11,"user":{"displayName":"심현우","userId":"05027025761987939753"}},"outputId":"913205e6-f563-4a92-d099-f0d57589f943"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Model initialized.\n"]}]},{"cell_type":"code","source":["print(\">>> Start Training\")\n","\n","# 배치 사이즈 설정\n","batch_size = 200\n","\n","for epoch in range(10): # 10 Epoch\n","    total_loss = 0\n","\n","    # [중요] 에폭 시작 시 메모리를 초기화하거나,\n","    # BPTT(Backprop Through Time)를 끊어줘야 함 (detach)\n","    model.memory.reset_state()  # 여기서는 매 에폭 리셋 전략 사용\n","\n","    # 데이터 로딩\n","    src_tr, dst_tr = train_data['src'], train_data['dst']\n","    t_tr, msg_tr = train_data['t'], train_data['msg']\n","\n","    model.train()\n","\n","    for i in range(0, len(src_tr), batch_size):\n","        optimizer.zero_grad()\n","\n","        # 배치 데이터 슬라이싱\n","        b_src = src_tr[i:i+batch_size]\n","        b_dst = dst_tr[i:i+batch_size]\n","        b_t = t_tr[i:i+batch_size]\n","        b_msg = msg_tr[i:i+batch_size]\n","\n","        # 1. Forward (Positive Samples)\n","        pos_pred = model(b_src, b_dst, b_t, b_msg)\n","\n","        # 2. Negative Sampling (간단히 랜덤 목적지 생성)\n","        # 실제로는 TGNMemory 충돌 방지를 위해 더 정교한 처리가 필요하나 Toy에서는 생략\n","        with torch.no_grad():\n","            neg_dst = torch.randint(0, num_nodes, (len(b_src),)).to(device)\n","\n","        # Negative에 대해서도 forward를 태워야 점수가 나옴\n","        # (주의: update_state가 두 번 호출되면 안 되므로, 실제 구현에선 memory update를 분리해야 함.\n","        # 여기서는 간단히 pos_pred 계산 시에만 update되었다고 가정)\n","        neg_pred = model.link_pred(\n","            torch.cat([model.gnn(model.memory(b_src)[0], torch.zeros((2,0), dtype=torch.long, device=device)),\n","                       model.gnn(model.memory(neg_dst)[0], torch.zeros((2,0), dtype=torch.long, device=device))], dim=1)\n","        )\n","\n","        # 3. Loss Calculation\n","        loss = criterion(pos_pred, torch.ones_like(pos_pred)) + \\\n","               criterion(neg_pred, torch.zeros_like(neg_pred))\n","\n","        # 4. Backward\n","        loss.backward()\n","        optimizer.step()\n","\n","        # [중요] 메모리 그래디언트 끊기 (다음 배치를 위해)\n","        model.memory.detach()\n","\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1:02d}, Loss: {total_loss:.4f}\")\n","\n","print(\">>> Training Finished\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":928},"id":"woWKz1pYRv1R","executionInfo":{"status":"error","timestamp":1765365813767,"user_tz":-540,"elapsed":86,"user":{"displayName":"심현우","userId":"05027025761987939753"}},"outputId":"04b346ee-bda0-4822-f341-21e83c1bf335"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> Start Training\n","torch.int64 torch.int64 torch.int64 torch.float32\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Index put requires the source and destination dtypes match, got Float for the destination and Long for the source.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2383804809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# 1. Forward (Positive Samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpos_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_dst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# 2. Negative Sampling (간단히 랜덤 목적지 생성)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-535670360.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, dst, t, msg)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# 4. 메모리 업데이트 (현재 배치의 정보를 기록)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/models/tgn.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, src, dst, t, raw_msg)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_msg_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_s_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_msg_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg_d_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/models/tgn.py\u001b[0m in \u001b[0;36m_update_memory\u001b[0;34m(self, n_id)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_updated_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_update\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_updated_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Index put requires the source and destination dtypes match, got Float for the destination and Long for the source."]}]},{"cell_type":"code","source":[],"metadata":{"id":"EXk1F_9IAJIb"},"execution_count":null,"outputs":[]}]}